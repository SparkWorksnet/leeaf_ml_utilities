{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "mount_file_id": "1Di-9A62j4sfBcmIS4P0I40EKX9jXK68-",
   "authorship_tag": "ABX9TyM0LJq1CGZ/NR4J4rNvGqOo"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PWmKfN_cQNCo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577206744,
     "user_tz": -180,
     "elapsed": 4837,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:15.852456Z",
     "start_time": "2023-08-30T15:56:15.841565Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "base_path = '/Users/amaxilatis/repositories/sparkworks/project-leeaf/dataset/olive_leaf'\n",
    "### tomato leaf disease\n",
    "TRAIN_PATH = f'{base_path}/train'\n",
    "VAL_PATH = f'{base_path}/valid'\n",
    "Test_path = f'{base_path}/test'\n",
    "\n",
    "IMAGE_SIZE = [256, 256]\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "EPOCHS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=TRAIN_PATH,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=False,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=VAL_PATH,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=False,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\"\n",
    ")"
   ],
   "metadata": {
    "id": "1QfObvrEQUUJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577235348,
     "user_tz": -180,
     "elapsed": 28609,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "outputId": "823ad177-06ae-476b-ec42-4bb9d51a3446",
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:17.598334Z",
     "start_time": "2023-08-30T15:56:17.290456Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5990 files belonging to 3 classes.\n",
      "Using 4792 files for training.\n",
      "Found 980 files belonging to 3 classes.\n",
      "Using 196 files for validation.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=Test_path,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    shuffle=False,\n",
    "\n",
    ")"
   ],
   "metadata": {
    "id": "t5jFiXza3Bmj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577237893,
     "user_tz": -180,
     "elapsed": 2561,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "outputId": "97414acf-3b04-4c3d-9280-5e510f13ff5a",
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:19.850064Z",
     "start_time": "2023-08-30T15:56:19.785809Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 970 files belonging to 3 classes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'best_model2.h5')"
   ],
   "metadata": {
    "id": "FwU1eSoa3BdA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577237894,
     "user_tz": -180,
     "elapsed": 5,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:34.952914Z",
     "start_time": "2023-08-30T15:56:34.949656Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomModelCheckpointCallback(tf.keras.callbacks.ModelCheckpoint):\n",
    "\n",
    "    def __init__(self, ignore_first=2, *args, **kwargs):\n",
    "        super(CustomModelCheckpointCallback, self).__init__(*args, **kwargs)\n",
    "        self.ignore_first = ignore_first\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch + 1 > self.ignore_first:\n",
    "            super().on_epoch_end(epoch, logs)"
   ],
   "metadata": {
    "id": "9EKIc7Ue3BTY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577237894,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:41.283836Z",
     "start_time": "2023-08-30T15:56:41.277238Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_callback = CustomModelCheckpointCallback(ignore_first=10, filepath=checkpoint_path, monitor='val_loss',\n",
    "                                                    mode='min', save_best_only=True, save_weights_only=False, verbose=1)"
   ],
   "metadata": {
    "id": "X8AIY5Ih3BGk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689577237895,
     "user_tz": -180,
     "elapsed": 5,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-08-30T15:56:43.840644Z",
     "start_time": "2023-08-30T15:56:43.834357Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "save_directory = 'transfer_models'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_and_evaluate_models(model_name, train_dataset, test_dataset):\n",
    "    # Load the pre-trained model\n",
    "    model = tf.keras.applications.__getattribute__(model_name)(input_shape=IMAGE_SIZE + [3], weights='imagenet',\n",
    "                                                               include_top=False)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(model.output)\n",
    "    prediction = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    existing_model = tf.keras.models.Model(inputs=model.input, outputs=prediction)\n",
    "\n",
    "    existing_model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=\"adam\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    existing_history = existing_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=40,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    y_pred = existing_model.predict(test_dataset)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, and F1 score with zero_division parameter\n",
    "    accuracy = accuracy_score(y_true, y_pred_labels)\n",
    "    precision = precision_score(y_true, y_pred_labels, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred_labels, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred_labels, average='weighted', zero_division=1)\n",
    "\n",
    "    model_save_path = os.path.join(save_directory, f'{model_name}.h5')\n",
    "    existing_model.save(model_save_path)\n",
    "\n",
    "    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}"
   ],
   "metadata": {
    "id": "zFcWx_bqQUjs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1689585253962,
     "user_tz": -180,
     "elapsed": 8016071,
     "user": {
      "displayName": "Themis Sarantakos",
      "userId": "01413615378689200014"
     }
    },
    "outputId": "301362bd-4f7f-4ac9-9e64-00765bedee1c",
    "ExecuteTime": {
     "end_time": "2023-08-30T16:01:36.883316Z",
     "start_time": "2023-08-30T16:01:36.880736Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Define the list of model names to train and evaluate\n",
    "model_names = ['ResNet50', 'VGG19', 'VGG16', 'InceptionV3', 'DenseNet121', 'MobileNetV2']\n",
    "evaluation_results = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T16:03:47.987081Z",
     "start_time": "2023-08-30T16:03:47.978073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "150/150 [==============================] - 126s 833ms/step - loss: 36.8757 - accuracy: 0.9034 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/40\n",
      "150/150 [==============================] - 124s 824ms/step - loss: 175.6618 - accuracy: 0.7611 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/40\n",
      "150/150 [==============================] - 122s 817ms/step - loss: 57.2361 - accuracy: 0.8362 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/40\n",
      "150/150 [==============================] - 263s 2s/step - loss: 25.4225 - accuracy: 0.8888 - val_loss: 0.0213 - val_accuracy: 0.9949\n",
      "Epoch 5/40\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 17.5048 - accuracy: 0.9061 - val_loss: 0.0988 - val_accuracy: 0.9949\n",
      "Epoch 6/40\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 13.7808 - accuracy: 0.9167 - val_loss: 0.2729 - val_accuracy: 0.9949\n",
      "Epoch 7/40\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 10.4716 - accuracy: 0.9282 - val_loss: 0.2678 - val_accuracy: 0.9949\n",
      "Epoch 8/40\n",
      "150/150 [==============================] - 123s 819ms/step - loss: 8.0360 - accuracy: 0.9359 - val_loss: 2.7964e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/40\n",
      "150/150 [==============================] - 123s 823ms/step - loss: 6.9567 - accuracy: 0.9382 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/40\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 5.9992 - accuracy: 0.9447 - val_loss: 6.0212e-08 - val_accuracy: 1.0000\n",
      "Epoch 11/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 5.7265 - accuracy: 0.9470\n",
      "Epoch 11: val_loss improved from inf to 0.00000, saving model to checkpoints/best_model2.h5\n",
      "150/150 [==============================] - 124s 828ms/step - loss: 5.7265 - accuracy: 0.9470 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.5361 - accuracy: 0.9543\n",
      "Epoch 12: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 835ms/step - loss: 4.5361 - accuracy: 0.9543 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.2145 - accuracy: 0.9566\n",
      "Epoch 13: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 836ms/step - loss: 4.2145 - accuracy: 0.9566 - val_loss: 0.3949 - val_accuracy: 0.9949\n",
      "Epoch 14/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 4.0112 - accuracy: 0.9587\n",
      "Epoch 14: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 829ms/step - loss: 4.0112 - accuracy: 0.9587 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 3.3576 - accuracy: 0.9633\n",
      "Epoch 15: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 827ms/step - loss: 3.3576 - accuracy: 0.9633 - val_loss: 0.7164 - val_accuracy: 0.9949\n",
      "Epoch 16/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.7185 - accuracy: 0.9683\n",
      "Epoch 16: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 2.7185 - accuracy: 0.9683 - val_loss: 0.0668 - val_accuracy: 0.9949\n",
      "Epoch 17/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 2.5050 - accuracy: 0.9689\n",
      "Epoch 17: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 826ms/step - loss: 2.5050 - accuracy: 0.9689 - val_loss: 0.8524 - val_accuracy: 0.9949\n",
      "Epoch 18/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.9814 - accuracy: 0.9693\n",
      "Epoch 18: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 825ms/step - loss: 1.9814 - accuracy: 0.9693 - val_loss: 0.8537 - val_accuracy: 0.9949\n",
      "Epoch 19/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.8812 - accuracy: 0.9752\n",
      "Epoch 19: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 828ms/step - loss: 1.8812 - accuracy: 0.9752 - val_loss: 0.6680 - val_accuracy: 0.9949\n",
      "Epoch 20/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.9181 - accuracy: 0.9760\n",
      "Epoch 20: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 829ms/step - loss: 1.9181 - accuracy: 0.9760 - val_loss: 0.8929 - val_accuracy: 0.9949\n",
      "Epoch 21/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.3431 - accuracy: 0.9766\n",
      "Epoch 21: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 829ms/step - loss: 1.3431 - accuracy: 0.9766 - val_loss: 1.5612 - val_accuracy: 0.9949\n",
      "Epoch 22/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.4163 - accuracy: 0.9758\n",
      "Epoch 22: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 126s 838ms/step - loss: 1.4163 - accuracy: 0.9758 - val_loss: 1.1150 - val_accuracy: 0.9949\n",
      "Epoch 23/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2290 - accuracy: 0.9781\n",
      "Epoch 23: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 834ms/step - loss: 1.2290 - accuracy: 0.9781 - val_loss: 1.1116 - val_accuracy: 0.9949\n",
      "Epoch 24/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.2968 - accuracy: 0.9800\n",
      "Epoch 24: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 835ms/step - loss: 1.2968 - accuracy: 0.9800 - val_loss: 1.2386 - val_accuracy: 0.9949\n",
      "Epoch 25/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.9804\n",
      "Epoch 25: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 831ms/step - loss: 1.0466 - accuracy: 0.9804 - val_loss: 0.2499 - val_accuracy: 0.9949\n",
      "Epoch 26/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0108 - accuracy: 0.9825\n",
      "Epoch 26: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 835ms/step - loss: 1.0108 - accuracy: 0.9825 - val_loss: 0.7640 - val_accuracy: 0.9949\n",
      "Epoch 27/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0294 - accuracy: 0.9843\n",
      "Epoch 27: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 126s 839ms/step - loss: 1.0294 - accuracy: 0.9843 - val_loss: 0.8350 - val_accuracy: 0.9949\n",
      "Epoch 28/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.9850\n",
      "Epoch 28: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 833ms/step - loss: 0.8223 - accuracy: 0.9850 - val_loss: 0.9398 - val_accuracy: 0.9949\n",
      "Epoch 29/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.9866\n",
      "Epoch 29: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 828ms/step - loss: 0.7739 - accuracy: 0.9866 - val_loss: 0.5024 - val_accuracy: 0.9898\n",
      "Epoch 30/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.9879\n",
      "Epoch 30: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 829ms/step - loss: 0.5765 - accuracy: 0.9879 - val_loss: 0.9264 - val_accuracy: 0.9847\n",
      "Epoch 31/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3462 - accuracy: 0.9900\n",
      "Epoch 31: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 834ms/step - loss: 0.3462 - accuracy: 0.9900 - val_loss: 4.7924 - val_accuracy: 0.9541\n",
      "Epoch 32/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9908\n",
      "Epoch 32: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 831ms/step - loss: 0.2888 - accuracy: 0.9908 - val_loss: 1.4550 - val_accuracy: 0.9745\n",
      "Epoch 33/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.9902\n",
      "Epoch 33: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 832ms/step - loss: 0.4293 - accuracy: 0.9902 - val_loss: 2.1237 - val_accuracy: 0.9745\n",
      "Epoch 34/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.9885\n",
      "Epoch 34: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 126s 838ms/step - loss: 0.4314 - accuracy: 0.9885 - val_loss: 0.8297 - val_accuracy: 0.9898\n",
      "Epoch 35/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.9885\n",
      "Epoch 35: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 833ms/step - loss: 0.3994 - accuracy: 0.9885 - val_loss: 0.2573 - val_accuracy: 0.9796\n",
      "Epoch 36/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9921\n",
      "Epoch 36: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 127s 845ms/step - loss: 0.2508 - accuracy: 0.9921 - val_loss: 1.5507 - val_accuracy: 0.9694\n",
      "Epoch 37/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.9919\n",
      "Epoch 37: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 835ms/step - loss: 0.2737 - accuracy: 0.9919 - val_loss: 3.4090 - val_accuracy: 0.9745\n",
      "Epoch 38/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9927\n",
      "Epoch 38: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 825ms/step - loss: 0.2149 - accuracy: 0.9927 - val_loss: 2.2159 - val_accuracy: 0.9745\n",
      "Epoch 39/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9937\n",
      "Epoch 39: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 125s 831ms/step - loss: 0.2068 - accuracy: 0.9937 - val_loss: 1.9114 - val_accuracy: 0.9694\n",
      "Epoch 40/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9931\n",
      "Epoch 40: val_loss did not improve from 0.00000\n",
      "150/150 [==============================] - 124s 828ms/step - loss: 0.2201 - accuracy: 0.9931 - val_loss: 1.3278 - val_accuracy: 0.9898\n",
      "31/31 [==============================] - 25s 789ms/step\n"
     ]
    }
   ],
   "source": [
    "model_name = model_names[0]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:29:37.159290Z",
     "start_time": "2023-08-30T16:03:51.491094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 4s 0us/step\n",
      "Epoch 1/40\n",
      "150/150 [==============================] - 493s 3s/step - loss: 31.2342 - accuracy: 0.9071 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/40\n",
      "150/150 [==============================] - ETA: 0s - loss: 149.4347 - accuracy: 0.7690"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model_name \u001B[38;5;241m=\u001B[39m model_names[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m evaluation_results[model_name] \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[18], line 25\u001B[0m, in \u001B[0;36mtrain_and_evaluate_models\u001B[0;34m(model_name, train_dataset, test_dataset)\u001B[0m\n\u001B[1;32m     18\u001B[0m existing_model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m     19\u001B[0m     loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     20\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     21\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     22\u001B[0m )\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m existing_history \u001B[38;5;241m=\u001B[39m \u001B[43mexisting_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     32\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Calculate precision, recall, and F1 score\u001B[39;00m\n\u001B[1;32m     35\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m existing_model\u001B[38;5;241m.\u001B[39mpredict(test_dataset)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/keras/engine/training.py:1694\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1681\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1682\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1692\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[1;32m   1693\u001B[0m     )\n\u001B[0;32m-> 1694\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1695\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1696\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1697\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1698\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1699\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1700\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1701\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1702\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1703\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1705\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1707\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1708\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1709\u001B[0m }\n\u001B[1;32m   1710\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/keras/engine/training.py:2040\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2037\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2038\u001B[0m ):\n\u001B[1;32m   2039\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2040\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2041\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   2042\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    917\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 919\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[1;32m    921\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    922\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/repositories/sparkworks/project-leeaf/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_name = model_names[1]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:06.418003Z",
     "start_time": "2023-08-30T17:29:37.162470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = model_names[2]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:06.419689Z",
     "start_time": "2023-08-30T17:46:06.419346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = model_names[3]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T17:46:06.420565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = model_names[4]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T17:46:06.424851Z",
     "start_time": "2023-08-30T17:46:06.421941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = model_names[5]\n",
    "evaluation_results[model_name] = train_and_evaluate_models(model_name, train_dataset, test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T17:46:06.423163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the evaluation results to a text file\n",
    "with open('evaluation_results.txt', 'w') as f:\n",
    "    for model_name, metrics in evaluation_results.items():\n",
    "        f.write(f'{model_name}\\n')\n",
    "        for metric, score in metrics.items():\n",
    "            f.write(f'{metric}: {score}\\n')\n",
    "        f.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-30T17:46:06.424087Z"
    }
   }
  }
 ]
}
